# ğŸŒŸ VisionMate â€“ AI-Powered Wearable Assistant for the Visually Impaired
*Created with â¤ï¸ by Achref Rhouma*

---

<!-- Banner -->
<img src="https://images.pexels.com/photos/6980526/pexels-photo-6980526.jpeg" alt="VisionMate Banner" width="100%">

---

## ğŸš€ Overview
**VisionMate** is a cutting-edge wearable assistant designed to empower blind and visually impaired individuals with real-time spatial awareness. Using **YOLOv8 object detection**, monocular depth estimation, and offline voice feedback, VisionMate provides immediate audio and haptic feedback to navigate the world confidently. Fully self-contained on a **Raspberry Pi**, this device requires no internet or external computers after setup.

---

## âœ¨ Features

| Feature | Description | Visual |
|---------|-------------|--------|
| ğŸ“· Object Detection | Detects people, doors, stairs, furniture, vehicles | <img src="https://images.pexels.com/photos/4386465/pexels-photo-4386465.jpeg" width="150px"> |
| ğŸ“ Depth Estimation | Monocular RGB-based distance measurements | <img src="https://images.pexels.com/photos/4145190/pexels-photo-4145190.jpeg" width="150px"> |
| ğŸ“¡ Ultrasonic Alerts | HC-SR04 sensor triggers vibration for nearby obstacles | <img src="https://images.pexels.com/photos/276452/pexels-photo-276452.jpeg" width="150px"> |
| ğŸ”Š Voice Feedback | On-device TTS announces objects and directions | <img src="https://images.pexels.com/photos/1181671/pexels-photo-1181671.jpeg" width="150px"> |
| ğŸ›ï¸ Tactile Buttons | Physical buttons for scene description & queries | <img src="https://images.pexels.com/photos/276517/pexels-photo-276517.jpeg" width="150px"> |
| ğŸŒ Offline Operation | Fully offline, no cloud dependency | <img src="https://images.pexels.com/photos/5077041/pexels-photo-5077041.jpeg" width="150px"> |

---

## ğŸ› ï¸ Tech Stack

- **Raspberry Pi** â€“ Core embedded system  
- **Python 3** â€“ Control and AI integration  
- **YOLOv8** â€“ Real-time object detection  
- **OpenCV** â€“ Image capture & processing  
- **ML-Depth-Pro** â€“ Monocular depth estimation  
- **HC-SR04 + Vibration Motor** â€“ Proximity feedback  
- **pyttsx3 / Pico TTS** â€“ Offline voice synthesis  
- **GPIO Buttons** â€“ Physical user interface  

---

## ğŸŒ Why VisionMate?

Current navigation solutions are expensive, bulky, or limited in functionality. VisionMate is **low-cost, portable, and intelligent**, combining vision, depth awareness, and intuitive interaction into a single wearable device. It enables users to navigate daily spaces with confidence and independence.

<img src="https://images.pexels.com/photos/4386476/pexels-photo-4386476.jpeg" alt="VisionMate in Action" width="800px">

---

## ğŸš§ Roadmap

- âœ… **MVP:** Object detection + depth estimation + TTS + tactile buttons  
- ğŸ”œ **Phase 2:** Voice-guided navigation for structured spaces  
- ğŸ”® **Phase 3:** Fully wearable vest/chest strap with modular sensors  
- ğŸ”­ **Future:** Smart glasses & haptic wristband integration, expanded object training  

<img src="https://images.pexels.com/photos/276517/pexels-photo-276517.jpeg" alt="Development Timeline" width="800px">

---

## ğŸ’¡ Creator Spotlight
**Achref Rhouma** â€“ AI enthusiast & accessibility advocate  
- Passion for inclusive tech  
- Expert in embedded AI & computer vision  
- Always designing with empathy and human-centered principles  

<img src="https://images.pexels.com/photos/220453/pexels-photo-220453.jpeg" alt="Creator Badge" width="150px">

---

## ğŸ‰ Demo / GIF Showcase
<img src="https://images.pexels.com/photos/4386465/pexels-photo-4386465.jpeg" alt="VisionMate Demo" width="600px">  
*See VisionMate detect objects, alert the user, and provide voice feedback in real time.*

---

## ğŸ”— GitHub
Check out the source code: [VisionMate Repository](https://github.com/AchrefRhm/VisionMate-AI-Powered-Wearable-Assistant-for-the-Visually-Impaired.git)

---

> âš¡ **Built with innovation and care by Achref Rhouma**, combining AI, accessibility, and human-centered design to make the world more navigable for everyone.
