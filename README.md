# ğŸŒŸ VisionMate â€“ AI-Powered Wearable Assistant for the Visually Impaired
*Created with â¤ï¸ by Achref Rhouma*

---

![VisionMate Banner](https://images.pexels.com/photos/6980526/pexels-photo-6980526.jpeg?auto=compress&cs=tinysrgb&w=1200&h=400&fit=crop)

---

## ğŸš€ Overview
**VisionMate** is a cutting-edge wearable assistant designed to empower blind and visually impaired individuals with real-time spatial awareness. Using **YOLOv8 object detection**, monocular depth estimation, and offline voice feedback, VisionMate provides immediate audio and haptic feedback to navigate the world confidently. Fully self-contained on a **Raspberry Pi**, this device requires no internet or external computers after setup.

---

## âœ¨ Features

| Feature | Description | Visual |
|---------|-------------|--------|
| ğŸ“· Object Detection | Detects people, doors, stairs, furniture, vehicles | ![Object Detection](https://images.pexels.com/photos/4386442/pexels-photo-4386442.jpeg?w=150&h=150&fit=crop) |
| ğŸ“ Depth Estimation | Monocular RGB-based distance measurements | ![Depth Estimation](https://images.pexels.com/photos/4386465/pexels-photo-4386465.jpeg?w=150&h=150&fit=crop) |
| ğŸ“¡ Ultrasonic Alerts | HC-SR04 sensor triggers vibration for nearby obstacles | ![Ultrasonic](https://images.pexels.com/photos/4386476/pexels-photo-4386476.jpeg?w=150&h=150&fit=crop) |
| ğŸ”Š Voice Feedback | On-device TTS announces objects and directions | ![Voice Feedback](https://images.pexels.com/photos/6980527/pexels-photo-6980527.jpeg?w=150&h=150&fit=crop) |
| ğŸ›ï¸ Tactile Buttons | Physical buttons for scene description & queries | ![Buttons](https://images.pexels.com/photos/3184420/pexels-photo-3184420.jpeg?w=150&h=150&fit=crop) |
| ğŸŒ Offline Operation | Fully offline, no cloud dependency | ![Offline](https://images.pexels.com/photos/3184418/pexels-photo-3184418.jpeg?w=150&h=150&fit=crop) |

---

## ğŸ› ï¸ Tech Stack

- **Raspberry Pi** â€“ Core embedded system  
- **Python 3** â€“ Control and AI integration  
- **YOLOv8** â€“ Real-time object detection  
- **OpenCV** â€“ Image capture & processing  
- **ML-Depth-Pro** â€“ Monocular depth estimation  
- **HC-SR04 + Vibration Motor** â€“ Proximity feedback  
- **pyttsx3 / Pico TTS** â€“ Offline voice synthesis  
- **GPIO Buttons** â€“ Physical user interface  

---

## ğŸŒ Why VisionMate?

Current navigation solutions are expensive, bulky, or limited in functionality. VisionMate is **low-cost, portable, and intelligent**, combining vision, depth awareness, and intuitive interaction into a single wearable device. It enables users to navigate daily spaces with confidence and independence.

![VisionMate in Action](https://images.pexels.com/photos/3184307/pexels-photo-3184307.jpeg?w=600&h=300&fit=crop)

---

## ğŸš§ Roadmap

- âœ… **MVP:** Object detection + depth estimation + TTS + tactile buttons  
- ğŸ”œ **Phase 2:** Voice-guided navigation for structured spaces  
- ğŸ”® **Phase 3:** Fully wearable vest/chest strap with modular sensors  
- ğŸ”­ **Future:** Smart glasses & haptic wristband integration, expanded object training  

![Timeline](https://images.pexels.com/photos/3184339/pexels-photo-3184339.jpeg?w=600&h=150&fit=crop)

---

## ğŸ’¡ Creator Spotlight
**Achref Rhouma** â€“ AI enthusiast & accessibility advocate  
- Passion for inclusive tech  
- Expert in embedded AI & computer vision  
- Always designing with empathy and human-centered principles

<div align="center">
<img src="https://images.pexels.com/photos/220453/pexels-photo-220453.jpeg?w=120&h=120&fit=crop" alt="Creator Badge">
</div>

---

## ğŸ‰ Demo / GIF Showcase
<div align="center">
<img src="https://images.pexels.com/photos/3184298/pexels-photo-3184298.jpeg?w=400&h=200&fit=crop" alt="VisionMate Demo">
*See VisionMate detect objects, alert the user, and provide voice feedback in real time.*
</div>

---

## ğŸ”— GitHub
Check out the source code: [VisionMate Repository](https://github.com/AchrefRhm/VisionMate-AI-Powered-Wearable-Assistant-for-the-Visually-Impaired.git)

---

> âš¡ **Built with innovation and care by Achref Rhouma**, combining AI, accessibility, and human-centered design to make the world more navigable for everyone.
