# VisionMate â€“ AI-Powered Wearable Assistant for the Visually Impaired
*Created with â¤ï¸ by Achref Rhouma*

---

![VisionMate Banner](https://via.placeholder.com/1200x400.png?text=VisionMate+AI+Wearable+Assistant)

---

## ðŸš€ Overview
**VisionMate** is a cutting-edge wearable assistant designed to empower blind and visually impaired individuals with real-time spatial awareness. Using **YOLOv8 object detection**, monocular depth estimation, and offline voice feedback, VisionMate provides immediate audio and haptic feedback to navigate the world confidently. Fully self-contained on a **Raspberry Pi**, this device requires no internet or external computers after setup.

---

## âœ¨ Features

| Feature | Description | GIF/Visual |
|---------|-------------|------------|
| ðŸ“· Object Detection | Detects people, doors, stairs, furniture, vehicles | ![Object Detection](https://via.placeholder.com/150.gif) |
| ðŸ“ Depth Estimation | Monocular RGB-based distance measurements | ![Depth Estimation](https://via.placeholder.com/150.gif) |
| ðŸ“¡ Ultrasonic Alerts | HC-SR04 sensor triggers vibration for nearby obstacles | ![Ultrasonic](https://via.placeholder.com/150.gif) |
| ðŸ”Š Voice Feedback | On-device TTS announces objects and directions | ![Voice Feedback](https://via.placeholder.com/150.gif) |
| ðŸŽ›ï¸ Tactile Buttons | Physical buttons for scene description & queries | ![Buttons](https://via.placeholder.com/150.gif) |
| ðŸŒ Offline Operation | Fully offline, no cloud dependency | ![Offline](https://via.placeholder.com/150.gif) |

---

## ðŸ› ï¸ Tech Stack

- **Raspberry Pi** â€“ Core embedded system  
- **Python 3** â€“ Control and AI integration  
- **YOLOv8** â€“ Real-time object detection  
- **OpenCV** â€“ Image capture & processing  
- **ML-Depth-Pro** â€“ Monocular depth estimation  
- **HC-SR04 + Vibration Motor** â€“ Proximity feedback  
- **pyttsx3 / Pico TTS** â€“ Offline voice synthesis  
- **GPIO Buttons** â€“ Physical user interface  

---

## ðŸŒ Why VisionMate?

Current navigation solutions are expensive, bulky, or limited in functionality. VisionMate is **low-cost, portable, and intelligent**, combining vision, depth awareness, and intuitive interaction into a single wearable device. It enables users to navigate daily spaces with confidence and independence.

![VisionMate in Action](https://via.placeholder.com/800x400.png?text=VisionMate+Wearable+Demo)

---

## ðŸš§ Roadmap

- âœ… **MVP:** Object detection + depth estimation + TTS + tactile buttons  
- ðŸ”œ **Phase 2:** Voice-guided navigation for structured spaces  
- ðŸ”® **Phase 3:** Fully wearable vest/chest strap with modular sensors  
- ðŸ”­ **Future:** Smart glasses & haptic wristband integration, expanded object training  

![Timeline](https://via.placeholder.com/800x150.png?text=Development+Timeline)

---

## ðŸ’¡ Creator Spotlight
**Achref Rhouma** â€“ AI enthusiast & accessibility advocate  
- Passion for inclusive tech  
- Expert in embedded AI & computer vision  
- Always designing with empathy and human-centered principles  

![Creator Badge](https://via.placeholder.com/150.png?text=Achref+Rhouma)

---

## ðŸŽ‰ Demo / GIF Showcase
![VisionMate Demo](https://via.placeholder.com/600x300.gif?text=VisionMate+Demo+GIF)  
*See VisionMate detect objects, alert the user, and provide voice feedback in real time.*

---

## ðŸ”— GitHub
Check out the source code: [VisionMate Repository](https://github.com/AchrefRhm/VisionMate-AI-Powered-Wearable-Assistant-for-the-Visually-Impaired.git)

---

> âš¡ **Built with innovation and care by Achref Rhouma**, combining AI, accessibility, and human-centered design to make the world more navigable for everyone.
